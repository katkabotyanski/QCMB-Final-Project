{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Load libraries \nimport os, gc, pickle, scipy.sparse\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom colorama import Fore, Back, Style\nfrom matplotlib.ticker import MaxNLocator\nfrom matplotlib.ticker import PercentFormatter\n\nfrom sklearn.model_selection import KFold\n# from sklearn.model_selection import GroupKFold\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.metrics import mean_squared_error\n\n# Load data\nDATA_DIR = \"/kaggle/input/open-problems-multimodal/\"\nFP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n\nFP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\nFP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\nFP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n\nFP_MULTIOME_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\nFP_MULTIOME_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\nFP_MULTIOME_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n\nFP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\nFP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")\n\n# Set params for model run\nLOADFILTER = True\nLOADSVD = True\nCROSS_VALIDATE = True\nSUBMIT = True","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:35:28.256430Z","iopub.execute_input":"2022-11-06T19:35:28.256995Z","iopub.status.idle":"2022-11-06T19:35:28.935015Z","shell.execute_reply.started":"2022-11-06T19:35:28.256889Z","shell.execute_reply":"2022-11-06T19:35:28.934035Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def correlation_score(y_true, y_pred):\n    \"\"\"Scores the predictions according to the competition rules. \n    \n    It is assumed that the predictions are not constant.\n    \n    Returns the average of each sample's Pearson correlation coefficient\"\"\"\n    if type(y_true) == pd.DataFrame: y_true = y_true.values\n    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n    corrsum = 0\n    for i in range(len(y_true)):\n        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n    return corrsum / len(y_true)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:35:28.936994Z","iopub.execute_input":"2022-11-06T19:35:28.937629Z","iopub.status.idle":"2022-11-06T19:35:28.944039Z","shell.execute_reply.started":"2022-11-06T19:35:28.937595Z","shell.execute_reply":"2022-11-06T19:35:28.942937Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"if not LOADFILTER:\n    %%time\n    # load training data\n    X_train = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n    print(f\"X_train shape: {str(X_train.shape):14} {X_train.size*4/1024/1024/1024:2.3f} GByte\")\n    # load test data\n    X_test = pd.read_hdf(FP_CITE_TEST_INPUTS)\n    print(f\"X_test shape: {str(X_test.shape):14} {X_test.size*4/1024/1024/1024:2.3f} GByte\")\n    # load test targets\n    y_train = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\n\n    y_columns = list(y_train.columns)\n    # y_rows = list(y_train.index)\n    # y_train = y_train.values\n\n    print(f\"y_train shape: {str(y_train.shape):14} {y_train.size*4/1024/1024/1024:2.3f} GByte\")\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:35:28.945515Z","iopub.execute_input":"2022-11-06T19:35:28.945864Z","iopub.status.idle":"2022-11-06T19:35:28.956463Z","shell.execute_reply.started":"2022-11-06T19:35:28.945834Z","shell.execute_reply":"2022-11-06T19:35:28.955386Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# metadata\nmetadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n# citeseq\nmetadata_df_citeseq = metadata_df[metadata_df.technology==\"citeseq\"]\nprint(metadata_df_citeseq.shape)\n# # multiome\n# metadata_df2 = metadata_df[metadata_df.technology==\"multiome\"]\n# print(metadata_df2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:35:28.958849Z","iopub.execute_input":"2022-11-06T19:35:28.959631Z","iopub.status.idle":"2022-11-06T19:35:29.566881Z","shell.execute_reply.started":"2022-11-06T19:35:28.959592Z","shell.execute_reply":"2022-11-06T19:35:29.565726Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(119651, 4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Filter training and test for important features\nInspiration taken from https://www.kaggle.com/code/ambrosm/msci-citeseq-quickstart/\n\nStarter templates have defined two sets of features:\n- `constant_cols` is the set of all features which are constant in the train training. These columns will be discarded immediately after loading.\n- `important_cols` is the set of all features whose name matches the name of a target protein. If a gene is named 'ENSG00000114013_CD86', it should be related to a protein named 'CD86'. These features will be used for the model unchanged, that is, they don't undergo dimensionality reduction. \n\nIt is likely not all important columns will be represented with this filtering as some genes won't have the exact protein label.\nAlso, it seems like there's no concern for including important columns as part of SVD.","metadata":{}},{"cell_type":"code","source":"if not LOADFILTER:\n    # get columns where all are zero\n    constant_cols = list(X_train.columns[(X_train == 0).all(axis=0).values]) + list(X_test.columns[(X_test == 0).all(axis=0).values])\n\n    important_cols = []\n    for y_col in y_train.columns:\n        important_cols += [x_col for x_col in X_train.columns if y_col in x_col and x_col not in constant_cols]\n\n    #save pickle files    \n    with open('constant_cols.pkl', 'wb') as f:\n        pickle.dump(constant_cols, f)\n    with open('important_cols.pkl', 'wb') as f:\n        pickle.dump(important_cols, f)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:35:29.568634Z","iopub.execute_input":"2022-11-06T19:35:29.569520Z","iopub.status.idle":"2022-11-06T19:35:29.579227Z","shell.execute_reply.started":"2022-11-06T19:35:29.569465Z","shell.execute_reply":"2022-11-06T19:35:29.578201Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if LOADFILTER:\n    # load pickle files \n    with open('/kaggle/input/citeseqtruncatedsvd512/constant_cols.pkl', 'rb') as f:\n        constant_cols = pickle.load(f)\n    with open('/kaggle/input/citeseqtruncatedsvd512/important_cols.pkl', 'rb') as f:\n        important_cols = pickle.load(f)\n    # set y_train to just values for training\n    #y_train = y_train.values\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:35:29.581250Z","iopub.execute_input":"2022-11-06T19:35:29.582044Z","iopub.status.idle":"2022-11-06T19:35:29.602180Z","shell.execute_reply.started":"2022-11-06T19:35:29.581993Z","shell.execute_reply":"2022-11-06T19:35:29.600651Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"%%time\n# Filter out constant genes and training set to sparse matrix\nX_train = pd.read_hdf(FP_CITE_TRAIN_INPUTS).drop(columns=constant_cols)\ncell_index = X_train.index\nmeta = metadata_df_citeseq.reindex(cell_index)\nX0 = X_train[important_cols].values\n# X_train = X_train.drop(columns = important_cols) # not sure whether to exclude important cols from SVD as they will be added into training set after SVD\nprint(f\"X_train shape after filtering: {str(X_train.shape):14} {X_train.size*4/1024/1024/1024:2.3f} GByte\")\ngc.collect()\nX_train = scipy.sparse.csr_matrix(X_train.values)\ngc.collect()\n\n\n# Filter out constant genes and test set to sparse matrix\nX_test = pd.read_hdf(FP_CITE_TEST_INPUTS).drop(columns=constant_cols)\ncell_index_test = X_test.index\nmeta_test = metadata_df_citeseq.reindex(cell_index_test)\nX0t = X_test[important_cols].values\n# X_test = X_test.drop(columns = important_cols)\nprint(f\"X_test shape after filtering: {str(X_test.shape):14} {X_test.size*4/1024/1024/1024:2.3f} GByte\")\ngc.collect()\nX_test = scipy.sparse.csr_matrix(X_test.values)\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:35:29.603803Z","iopub.execute_input":"2022-11-06T19:35:29.604562Z","iopub.status.idle":"2022-11-06T19:38:53.374914Z","shell.execute_reply.started":"2022-11-06T19:35:29.604505Z","shell.execute_reply":"2022-11-06T19:38:53.373632Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"X_train shape after filtering: (70988, 20856) 5.515 GByte\nX_test shape after filtering: (48663, 20856) 3.781 GByte\nCPU times: user 2min 31s, sys: 22.7 s, total: 2min 54s\nWall time: 3min 23s\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"# Apply Truncated SVD","metadata":{}},{"cell_type":"code","source":"%%time\nif not LOADSVD:\n    # Apply the singular value decomposition \n    both = scipy.sparse.vstack([X_train, X_test])\n    assert both.shape[0] == 119651\n    print(f\"Shape of both before SVD: {both.shape}\")\n    svd = TruncatedSVD(n_components=512, random_state=1) # 512\n    both = svd.fit_transform(both)\n    print(f\"Shape of both after SVD:  {both.shape}\")\n\n    # save truncated training and test sets\n    X_train = both[:70988]\n    X_test = both[70988:]\n    with open('train_Citeseq_truncated_512.pkl', 'wb') as f:\n        pickle.dump(X_train, f)\n\n    with open('test_Citeseq_truncated_512.pkl', 'wb') as f:\n        pickle.dump(X_test, f)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:38:53.376836Z","iopub.execute_input":"2022-11-06T19:38:53.377497Z","iopub.status.idle":"2022-11-06T19:38:53.387591Z","shell.execute_reply.started":"2022-11-06T19:38:53.377455Z","shell.execute_reply":"2022-11-06T19:38:53.386294Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"if LOADSVD:\n    with open('/kaggle/input/citeseqtruncatedsvd512/train_Citeseq_truncated_512.pkl','rb') as f: X_train = pickle.load(f)\n    with open('/kaggle/input/citeseqtruncatedsvd512/test_Citeseq_truncated_512.pkl','rb') as f: X_test = pickle.load(f)\n    X_train.shape, X_test.shape\n\n# Hstack the svd training set (basically everything that isn't constant) with the important features\nX_train = np.hstack([X_train, X0])\nX_test = np.hstack([X_test, X0t])\nprint(f\"Reduced X shape:  {str(X_train.shape):14} {X_train.size*4/1024/1024/1024:2.3f} GByte\")\nprint(f\"Reduced Xt shape: {str(X_test.shape):14} {X_test.size*4/1024/1024/1024:2.3f} GByte\")","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:38:53.389025Z","iopub.execute_input":"2022-11-06T19:38:53.389402Z","iopub.status.idle":"2022-11-06T19:38:57.091370Z","shell.execute_reply.started":"2022-11-06T19:38:53.389367Z","shell.execute_reply":"2022-11-06T19:38:57.090009Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Reduced X shape:  (70988, 656)   0.173 GByte\nReduced Xt shape: (48663, 656)   0.119 GByte\n","output_type":"stream"}]},{"cell_type":"code","source":"# load training targets\n# use values only for training\ny_train = pd.read_hdf(FP_CITE_TRAIN_TARGETS)\ny_train = y_train.values","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:38:57.095496Z","iopub.execute_input":"2022-11-06T19:38:57.096287Z","iopub.status.idle":"2022-11-06T19:38:57.752233Z","shell.execute_reply.started":"2022-11-06T19:38:57.096244Z","shell.execute_reply":"2022-11-06T19:38:57.750814Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## linear regression with Ridge regularization","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\ndef create_model():\n    model = Ridge(copy_X=False)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:38:57.753761Z","iopub.execute_input":"2022-11-06T19:38:57.754136Z","iopub.status.idle":"2022-11-06T19:38:57.759692Z","shell.execute_reply.started":"2022-11-06T19:38:57.754103Z","shell.execute_reply":"2022-11-06T19:38:57.758586Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Cross validation\n\n5 fold cross validation to QC model.\nThis should flag problems like overfitting or selection bias if results from cross validation are poor.","metadata":{}},{"cell_type":"code","source":"%%time\n# 5-fold Cross-validation\nkf = KFold(n_splits=5, shuffle=True, random_state=1)\nscore_list = []\nfor fold, (idx_tr, idx_va) in enumerate(kf.split(X_train)):\n    model = None\n    gc.collect()\n    X_tr = X_train[idx_tr] # creates a copy, https://numpy.org/doc/stable/user/basics.copies.html\n    y_tr = y_train[idx_tr]\n    del idx_tr\n    \n    model = create_model()\n    model.fit(X_tr, y_tr)\n    del X_tr, y_tr\n    gc.collect()\n\n    # We validate the model\n    X_va = X_train[idx_va]\n    y_va = y_train[idx_va]\n    del idx_va\n    y_va_pred = model.predict(X_va)\n    mse = mean_squared_error(y_va, y_va_pred)\n    corrscore = correlation_score(y_va, y_va_pred)\n    del X_va, y_va\n\n    print(f\"Fold {fold}: mse = {mse:.5f}, corr =  {corrscore:.3f}\")\n    score_list.append((mse, corrscore))\n\n# Show overall score\nresult_df = pd.DataFrame(score_list, columns=['mse', 'corrscore'])\nprint(f\"{Fore.GREEN}{Style.BRIGHT}{X_train.shape} Average  mse = {result_df.mse.mean():.5f}; corr = {result_df.corrscore.mean():.3f}{Style.RESET_ALL}\")\nresult_df.to_csv('citeseq_ridge_crossval_res.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:38:57.761007Z","iopub.execute_input":"2022-11-06T19:38:57.761493Z","iopub.status.idle":"2022-11-06T19:39:10.112184Z","shell.execute_reply.started":"2022-11-06T19:38:57.761461Z","shell.execute_reply":"2022-11-06T19:39:10.111092Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Fold 0: mse = 2.54443, corr =  0.893\nFold 1: mse = 2.54259, corr =  0.893\nFold 2: mse = 2.54726, corr =  0.893\nFold 3: mse = 2.55948, corr =  0.892\nFold 4: mse = 2.54676, corr =  0.892\n\u001b[32m\u001b[1m(70988, 656) Average  mse = 2.54810; corr = 0.892\u001b[0m\nCPU times: user 18.3 s, sys: 3.59 s, total: 21.9 s\nWall time: 12.3 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Adjust params if required depending on cross validation results to tune model before retraining on full training data","metadata":{}},{"cell_type":"markdown","source":"## Retrain (given satisfactory cross validation)","metadata":{}},{"cell_type":"code","source":"# We retrain the model and then delete the training data, which is no longer needed\nmodel, score_list, result_df = None, None, None # free the RAM occupied by the old model\ngc.collect()\nmodel = Ridge(copy_X=False) # we overwrite the training data\nmodel.fit(X_train, y_train)\n\ndel X_train, y_train # free the RAM\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:39:10.113641Z","iopub.execute_input":"2022-11-06T19:39:10.114214Z","iopub.status.idle":"2022-11-06T19:39:11.137188Z","shell.execute_reply.started":"2022-11-06T19:39:10.114180Z","shell.execute_reply":"2022-11-06T19:39:11.135913Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"## Predict ","metadata":{}},{"cell_type":"code","source":"%%time\ntest_pred = model.predict(X_test)\ndel X_test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:39:11.139060Z","iopub.execute_input":"2022-11-06T19:39:11.139832Z","iopub.status.idle":"2022-11-06T19:39:11.512484Z","shell.execute_reply.started":"2022-11-06T19:39:11.139783Z","shell.execute_reply":"2022-11-06T19:39:11.511247Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"CPU times: user 763 ms, sys: 300 ms, total: 1.06 s\nWall time: 363 ms\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"23"},"metadata":{}}]},{"cell_type":"markdown","source":"# Submission\n\nThe CITEseq test predictions have 48663 rows (i.e., cells) and 140 columns (i.e. proteins). 48663 * 140 = 6812820. The final submission will have 65744180 rows, of which the first 6812820 are for the CITEseq predictions and the remaining 58931360 for the Multiome predictions. ","metadata":{}},{"cell_type":"code","source":"%%time\nif SUBMIT:\n    # generate submission for CITEseq\n    submission = pd.read_csv(FP_SUBMISSION,index_col='row_id', squeeze=True)\n    submission.iloc[:len(test_pred.ravel())] = test_pred.ravel()\n    assert not submission.isna().any()\n\n    submission.to_csv('submission_citeseq_ridge.csv')\n    display(submission)","metadata":{"execution":{"iopub.status.busy":"2022-11-06T19:43:02.496624Z","iopub.execute_input":"2022-11-06T19:43:02.497774Z","iopub.status.idle":"2022-11-06T19:45:51.304852Z","shell.execute_reply.started":"2022-11-06T19:43:02.497708Z","shell.execute_reply":"2022-11-06T19:45:51.303558Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"row_id\n0           0.293109\n1           0.478517\n2           0.836718\n3           4.669548\n4           5.313168\n              ...   \n65744175    0.000000\n65744176    0.000000\n65744177    0.000000\n65744178    0.000000\n65744179    0.000000\nName: target, Length: 65744180, dtype: float64"},"metadata":{}},{"name":"stdout","text":"CPU times: user 2min 36s, sys: 4.35 s, total: 2min 40s\nWall time: 2min 48s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}